{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c84a50",
   "metadata": {},
   "source": [
    "### Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93460a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a95af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT INTO t_event_info (meta_event, meta_session, meta_event_name, meta_session_name)\n",
    "# VALUES\n",
    "# \t(\"I_R01_2025-03-30\", \"R1\", \"Sonoma\"),\n",
    "# \t(\"I_R02_2025-04-27\", \"R1\", \"Circuit of the Americas\"),\n",
    "# \t(\"I_R03_2025-05-18\", \"R1\", \"Sebring International Raceway\"),\n",
    "# \t(\"I_R04_2025-07-20\", \"R1\", \"Virginia International Raceway\"),\n",
    "# \t(\"I_R05_2025-08-17\", \"R1\", \"Road America\"),\n",
    "# \t(\"I_R06_2025-09-07\", \"R1\", \"Barber Motorsports Park\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b1b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f4866c5",
   "metadata": {},
   "source": [
    "### t_best_lap_data (best_lap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f546011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_barber_best_lap_data.csv')\n",
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 2 ('99_Best 10 Laps By Driver_Race 2_Anonymized.CSV', 'R2_barber_best_lap_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_cota_best_lap_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 2 ('99_Best 10 Laps By Driver_ Race 2_Anonymized.CSV', 'R2_cota_best_lap_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 1 ('99_Best 10 Laps By Driver_Race 1.CSV', 'R1_indianapolis_best_lap_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 2 ('99_Best 10 Laps By Driver_Race 2.CSV', 'R2_indianapolis_best_lap_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_road_america_best_lap_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 2 ('99_Best 10 Laps By Driver_Race 2_Anonymized.CSV', 'R2_road_america_best_lap_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_sebring_best_lap_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 2 ('99_Best 10 Laps By Driver_Race 2_Anonymized.CSV', 'R2_sebring_best_lap_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_sonoma_best_lap_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 2 ('99_Best 10 Laps By Driver_Race 2_Anonymized.CSV', 'R2_sonoma_best_lap_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 1 ('99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', 'R1_vir_best_lap_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 2 ('99_Best 10 Laps By Driver_Race 2_Anonymized.CSV', 'R2_vir_best_lap_data.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file_name = [\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_Race 2_Anonymized.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_ Race 2_Anonymized.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1.CSV', '99_Best 10 Laps By Driver_Race 2.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_Race 2_Anonymized.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_Race 2_Anonymized.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_Race 2_Anonymized.CSV'],\n",
    "    ['99_Best 10 Laps By Driver_Race 1_Anonymized.CSV', '99_Best 10 Laps By Driver_Race 2_Anonymized.CSV']\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_best_lap_data.csv', 'R2_barber_best_lap_data.csv'],\n",
    "    ['R1_cota_best_lap_data.csv', 'R2_cota_best_lap_data.csv'],\n",
    "    ['R1_indianapolis_best_lap_data.csv', 'R2_indianapolis_best_lap_data.csv'],\n",
    "    ['R1_road_america_best_lap_data.csv', 'R2_road_america_best_lap_data.csv'],\n",
    "    ['R1_sebring_best_lap_data.csv', 'R2_sebring_best_lap_data.csv'],\n",
    "    ['R1_sonoma_best_lap_data.csv', 'R2_sonoma_best_lap_data.csv'],\n",
    "    ['R1_vir_best_lap_data.csv', 'R2_vir_best_lap_data.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_track_id = [\"I_R06_2025-09-07\", \"I_R02_2025-04-27\", \"I_R07_2025-10-19\", \"I_R05_2025-08-17\", \"I_R03_2025-05-18\", \"I_R01_2025-03-30\", \"I_R04_2025-07-20\"]\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_t_id, r_n, list_i_path, list_o_path in zip(race_track, race_track_id, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t, r_t_id), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            test_df = pd.read_csv(\n",
    "                f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                usecols=[\"NUMBER\", \"TOTAL_DRIVER_LAPS\", \"BESTLAP_1\", \"BESTLAP_1_LAPNUM\", \"BESTLAP_2\", \"BESTLAP_2_LAPNUM\", \"BESTLAP_3\", \"BESTLAP_3_LAPNUM\", \"BESTLAP_4\", \"BESTLAP_4_LAPNUM\", \"BESTLAP_5\", \"BESTLAP_5_LAPNUM\", \"BESTLAP_6\", \"BESTLAP_6_LAPNUM\", \"BESTLAP_7\", \"BESTLAP_7_LAPNUM\", \"BESTLAP_8\", \"BESTLAP_8_LAPNUM\", \"BESTLAP_9\", \"BESTLAP_9_LAPNUM\", \"BESTLAP_10\", \"BESTLAP_10_LAPNUM\", \"AVERAGE\"],\n",
    "                sep=\";\",\n",
    "                dtype={'NUMBER': str}\n",
    "            )\n",
    "\n",
    "            test_df[\"meta_event\"] = r_t_id\n",
    "            test_df[\"meta_session\"] = f\"R{s}\"\n",
    "            \n",
    "                        \n",
    "            # Convert columns to lowercase and strip spaces\n",
    "            test_df.columns = [col.strip().lower() for col in test_df.columns]\n",
    "            test_df.replace(\"\", pd.NA, inplace=True)\n",
    "            test_df[\"total_driver_laps\"] = test_df[\"total_driver_laps\"].astype(int)\n",
    "\n",
    "            lap_time_cols = [c for c in test_df.columns if \"bestlap\" in c or c == \"average\"]\n",
    "\n",
    "            for c in lap_time_cols:\n",
    "                test_df[c] = test_df[c].astype(str).replace(\"nan\", None)\n",
    "                \n",
    "            \n",
    "            test_df = test_df[[\"meta_event\", \"meta_session\", *[col for col in test_df.columns if col not in [\"meta_event\", \"meta_session\"]]]]\n",
    "\n",
    "            test_df.to_csv(\n",
    "                f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fb17d",
   "metadata": {},
   "source": [
    "### t_lap_time_data (lap_time) [need some work for barber and indianapolis and VIR R2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81ee1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def process_vehicle_sequences(test_df):\n",
    "    # Ensure timestamp is datetime\n",
    "    test_df.loc[:, 'timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    \n",
    "    all_cleaned = []\n",
    "\n",
    "    for vid in test_df['vehicle_id'].unique():\n",
    "        vehicle_df = (\n",
    "            test_df[(test_df['vehicle_id'] == vid) & (test_df['value'] > 1000)]\n",
    "            .sort_values(by='timestamp')\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Identify all sequences (continuous within 10 minutes)\n",
    "        sequences = []\n",
    "        start_idx = 0\n",
    "        for i in range(1, len(vehicle_df)):\n",
    "            diff = vehicle_df.loc[i, 'timestamp'] - vehicle_df.loc[i-1, 'timestamp']\n",
    "            if diff > timedelta(minutes=10):\n",
    "                sequences.append((start_idx, i - 1))\n",
    "                start_idx = i\n",
    "        sequences.append((start_idx, len(vehicle_df) - 1))\n",
    "\n",
    "        if not sequences:\n",
    "            continue\n",
    "\n",
    "        # Find longest sequence\n",
    "        longest_seq = max(sequences, key=lambda x: x[1] - x[0] + 1)\n",
    "        seq_df = vehicle_df.iloc[longest_seq[0] : longest_seq[1] + 1].copy().reset_index(drop=True)\n",
    "\n",
    "        # --- Fix lap anomalies ---\n",
    "        seq_df['lap'] = pd.to_numeric(seq_df['lap'], errors='coerce')\n",
    "        seq_df.loc[seq_df['lap'] == 32768, 'lap'] = None\n",
    "\n",
    "        # Handle laps\n",
    "        if not seq_df['lap'].dropna().empty:\n",
    "            seq_df['lap'] = seq_df['lap'].ffill().bfill()\n",
    "            for i in range(1, len(seq_df)):\n",
    "                # use .iloc instead of .loc to avoid index key errors\n",
    "                if pd.isna(seq_df.iloc[i]['lap']):\n",
    "                    seq_df.loc[i, 'lap'] = seq_df.iloc[i-1]['lap'] + 1\n",
    "                elif seq_df.iloc[i]['lap'] <= seq_df.iloc[i-1]['lap']:\n",
    "                    seq_df.loc[i, 'lap'] = seq_df.iloc[i-1]['lap'] + 1\n",
    "        else:\n",
    "            seq_df['lap'] = range(1, len(seq_df) + 1)\n",
    "\n",
    "        # Fill remaining NaNs (edge safety)\n",
    "        seq_df['lap'] = seq_df['lap'].ffill().bfill()\n",
    "        seq_df['lap'] = seq_df['lap'].astype(int)\n",
    "\n",
    "        all_cleaned.append(seq_df)\n",
    "\n",
    "    final_df = pd.concat(all_cleaned, ignore_index=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66fb98d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> barber-motorsports-park barber 1 ('barber_lap_time.csv', 'R1_barber_lap_time.csv')\n",
      "error at ('barber-motorsports-park', 'barber', 1) :\n",
      " Usecols do not match columns, columns expected but not found: ['value']\n",
      "--> barber-motorsports-park barber 2 ('barber_lap_time.csv', 'R2_barber_lap_time.csv')\n",
      "error at ('barber-motorsports-park', 'barber', 2) :\n",
      " Usecols do not match columns, columns expected but not found: ['value']\n",
      "--> circuit-of-the-americas COTA 1 ('COTA_lap_time_R1.csv', 'R1_cota_lap_time.csv')\n",
      "--> circuit-of-the-americas COTA 2 ('COTA_lap_time_R2.csv', 'R2_cota_lap_time.csv')\n",
      "--> indianapolis indianapolis 1 ('R1_indianapolis_motor_speedway_lap_time.csv', 'R1_indianapolis_lap_time.csv')\n",
      "error at ('indianapolis', 'indianapolis', 1) :\n",
      " Usecols do not match columns, columns expected but not found: ['value']\n",
      "--> indianapolis indianapolis 2 ('R2_indianapolis_motor_speedway_lap_time.csv', 'R2_indianapolis_lap_time.csv')\n",
      "error at ('indianapolis', 'indianapolis', 2) :\n",
      " Usecols do not match columns, columns expected but not found: ['value']\n",
      "--> road-america Road America 1 ('road_america_lap_time_R1.csv', 'R1_road_america_lap_time.csv')\n",
      "--> road-america Road America 2 ('road_america_lap_time_R2.csv', 'R2_road_america_lap_time.csv')\n",
      "--> sebring Sebring 1 ('sebring_lap_time_R1.csv', 'R1_sebring_lap_time.csv')\n",
      "--> sebring Sebring 2 ('sebring_lap_time_R2.csv', 'R2_sebring_lap_time.csv')\n",
      "--> sonoma Sonoma 1 ('sonoma_lap_time_R1.csv', 'R1_sonoma_lap_time.csv')\n",
      "--> sonoma Sonoma 2 ('sonoma_lap_time_R2.csv', 'R2_sonoma_lap_time.csv')\n",
      "--> virginia-international-raceway VIR 1 ('vir_lap_time_R1.csv', 'R1_vir_lap_time.csv')\n",
      "--> virginia-international-raceway VIR 2 ('', 'R2_vir_lap_time.csv')\n",
      "error at ('virginia-international-raceway', 'VIR', 2) :\n",
      " [Errno 2] No such file or directory: 'dataset\\\\virginia-international-raceway\\\\VIR\\\\Race 2\\\\'\n"
     ]
    }
   ],
   "source": [
    "input_file_name = [\n",
    "    ['barber_lap_time.csv', 'barber_lap_time.csv'],\n",
    "    ['COTA_lap_time_R1.csv', 'COTA_lap_time_R2.csv'],\n",
    "    ['R1_indianapolis_motor_speedway_lap_time.csv', 'R2_indianapolis_motor_speedway_lap_time.csv'],\n",
    "    ['road_america_lap_time_R1.csv', 'road_america_lap_time_R2.csv'],\n",
    "    ['sebring_lap_time_R1.csv', 'sebring_lap_time_R2.csv'],\n",
    "    ['sonoma_lap_time_R1.csv', 'sonoma_lap_time_R2.csv'],\n",
    "    ['vir_lap_time_R1.csv', ''] #vir_lap_time_R2.csv\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_lap_time.csv', 'R2_barber_lap_time.csv'],\n",
    "    ['R1_cota_lap_time.csv', 'R2_cota_lap_time.csv'],\n",
    "    ['R1_indianapolis_lap_time.csv', 'R2_indianapolis_lap_time.csv'],\n",
    "    ['R1_road_america_lap_time.csv', 'R2_road_america_lap_time.csv'],\n",
    "    ['R1_sebring_lap_time.csv', 'R2_sebring_lap_time.csv'],\n",
    "    ['R1_sonoma_lap_time.csv', 'R2_sonoma_lap_time.csv'],\n",
    "    ['R1_vir_lap_time.csv', 'R2_vir_lap_time.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_n, list_i_path, list_o_path in zip(race_track, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            \n",
    "            test_df = pd.read_csv(\n",
    "                f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                usecols=['meta_event', 'meta_session', 'timestamp', 'vehicle_id', 'lap', 'value']\n",
    "            )\n",
    "            test_df = test_df[['meta_event', 'meta_session', 'timestamp', 'vehicle_id', 'lap', 'value']]\n",
    "\n",
    "            filtered_df = process_vehicle_sequences(test_df)\n",
    "            filtered_df.to_csv(\n",
    "                f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782701d",
   "metadata": {},
   "source": [
    "### t_race_result_data (race_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bca75606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 1 ('03_Provisional Results_Race 1_Anonymized.CSV', 'R1_barber_race_results.csv')\n",
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 2 ('03_Provisional Results_Race 2_Anonymized.CSV', 'R2_barber_race_results.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 1 ('00_Results GR Cup Race 1 Official_Anonymized.CSV', 'R1_cota_race_results.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 2 ('03_Provisional Results_ Race 2_Anonymized.CSV', 'R2_cota_race_results.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 1 ('03_GR Cup Race 1 Official Results.CSV', 'R1_indianapolis_race_results.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 2 ('03_GR Cup Race 2 Official Results.CSV', 'R2_indianapolis_race_results.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 1 ('03_Provisional Results_Race 1_Anonymized.CSV', 'R1_road_america_race_results.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 2 ('03_Provisional Results_Race 2_Anonymized.CSV', 'R2_road_america_race_results.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 1 ('03_Provisional Results_Race 1_Anonymized.CSV', 'R1_sebring_race_results.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 2 ('00_Results GR Race 2 Official_Anonymized.CSV', 'R2_sebring_race_results.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 1 ('03_Results_Anonymized.CSV', 'R1_sonoma_race_results.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 2 ('03_Provisional_Results_Race 2_Anonymized.CSV', 'R2_sonoma_race_results.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 1 ('03_Provisional Results_Race 1_Anonymized.CSV', 'R1_vir_race_results.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 2 ('03_Provisional Results_Race 2_Anonymized.CSV', 'R2_vir_race_results.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file_name = [\n",
    "    ['03_Provisional Results_Race 1_Anonymized.CSV', '03_Provisional Results_Race 2_Anonymized.CSV'],\n",
    "    ['00_Results GR Cup Race 1 Official_Anonymized.CSV', '03_Provisional Results_ Race 2_Anonymized.CSV'],\n",
    "    ['03_GR Cup Race 1 Official Results.CSV', '03_GR Cup Race 2 Official Results.CSV'],\n",
    "    ['03_Provisional Results_Race 1_Anonymized.CSV', '03_Provisional Results_Race 2_Anonymized.CSV'],\n",
    "    ['03_Provisional Results_Race 1_Anonymized.CSV', '00_Results GR Race 2 Official_Anonymized.CSV'],\n",
    "    ['03_Results_Anonymized.CSV', '03_Provisional_Results_Race 2_Anonymized.CSV'],\n",
    "    ['03_Provisional Results_Race 1_Anonymized.CSV', '03_Provisional Results_Race 2_Anonymized.CSV']\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_race_results.csv', 'R2_barber_race_results.csv'],\n",
    "    ['R1_cota_race_results.csv', 'R2_cota_race_results.csv'],\n",
    "    ['R1_indianapolis_race_results.csv', 'R2_indianapolis_race_results.csv'],\n",
    "    ['R1_road_america_race_results.csv', 'R2_road_america_race_results.csv'],\n",
    "    ['R1_sebring_race_results.csv', 'R2_sebring_race_results.csv'],\n",
    "    ['R1_sonoma_race_results.csv', 'R2_sonoma_race_results.csv'],\n",
    "    ['R1_vir_race_results.csv', 'R2_vir_race_results.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_track_id = [\"I_R06_2025-09-07\", \"I_R02_2025-04-27\", \"I_R07_2025-10-19\", \"I_R05_2025-08-17\", \"I_R03_2025-05-18\", \"I_R01_2025-03-30\", \"I_R04_2025-07-20\"]\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_t_id, r_n, list_i_path, list_o_path in zip(race_track, race_track_id, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t, r_t_id), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            test_df = pd.read_csv(\n",
    "                f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                usecols=[\"POSITION\", \"NUMBER\", \"LAPS\", \"TOTAL_TIME\", \"GAP_FIRST\", \"GAP_PREVIOUS\", \"FL_LAPNUM\", \"FL_TIME\", \"FL_KPH\"],\n",
    "                sep=\";\",\n",
    "                dtype={'NUMBER': str}\n",
    "            )\n",
    "            test_df[\"meta_event\"] = r_t_id\n",
    "            test_df[\"meta_session\"] = f\"R{s}\"\n",
    "            test_df = test_df[[\"meta_event\", \"meta_session\", \"POSITION\", \"NUMBER\", \"LAPS\", \"TOTAL_TIME\", \"GAP_FIRST\", \"GAP_PREVIOUS\", \"FL_LAPNUM\", \"FL_TIME\", \"FL_KPH\"]]\n",
    "            test_df[\"POSITION\"] = test_df[\"POSITION\"].astype('Int64')\n",
    "            test_df.to_csv(\n",
    "                f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a79942",
   "metadata": {},
   "source": [
    "### t_sector_data (sector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66be6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try time-duration (e.g., 1:54.168 or 0:33.413)\n",
    "def parse_time_like(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        return val\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        parts = value.split(\":\")\n",
    "        if len(parts) == 1:\n",
    "            return float(parts)\n",
    "        \n",
    "        elif len(parts) == 2:\n",
    "            # MM:SS.sss -> convert to total seconds\n",
    "            minutes, seconds = parts\n",
    "            total_seconds = float(minutes) * 60 + float(seconds)\n",
    "            return total_seconds\n",
    "\n",
    "        elif len(parts) == 3:\n",
    "            # HH:MM:SS.sss -> convert to total seconds\n",
    "            hours, minutes, seconds = parts\n",
    "            total_seconds = (float(hours) * 3600) + (float(minutes) * 60) + float(seconds)\n",
    "            return total_seconds\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def convert_columns(df):\n",
    "    for col in df.columns:\n",
    "        # Try numeric conversion\n",
    "        try:\n",
    "            df.loc[:,col] = pd.to_numeric(df[col], errors='raise')\n",
    "            continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # Try datetime conversion\n",
    "        try:\n",
    "            df.loc[:, col] = pd.to_datetime(df[col], errors='raise', format='%H:%M:%S.%f')\n",
    "            continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        sample_value = df[col].dropna().astype(str).iloc[0] if df[col].dropna().shape[0] > 0 else \"\"\n",
    "        \n",
    "        df.loc[:, col] = df[col].apply(parse_time_like)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4088a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_barber_sector_data.csv')\n",
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 2 ('23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV', 'R2_barber_sector_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_cota_sector_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 2 ('23_AnalysisEnduranceWithSections_ Race 2_Anonymized.CSV', 'R2_cota_sector_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 1 ('23_AnalysisEnduranceWithSections_Race 1.CSV', 'R1_indianapolis_sector_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 2 ('23_AnalysisEnduranceWithSections_Race 2.CSV', 'R2_indianapolis_sector_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_road_america_sector_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 2 ('23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV', 'R2_road_america_sector_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_sebring_sector_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 2 ('23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV', 'R2_sebring_sector_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_sonoma_sector_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 2 ('23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV', 'R2_sonoma_sector_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 1 ('23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', 'R1_vir_sector_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 2 ('23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV', 'R2_vir_sector_data.csv')\n"
     ]
    }
   ],
   "source": [
    "input_file_name = [\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_ Race 2_Anonymized.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1.CSV', '23_AnalysisEnduranceWithSections_Race 2.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV'],\n",
    "    ['23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV', '23_AnalysisEnduranceWithSections_Race 2_Anonymized.CSV']\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_sector_data.csv', 'R2_barber_sector_data.csv'],\n",
    "    ['R1_cota_sector_data.csv', 'R2_cota_sector_data.csv'],\n",
    "    ['R1_indianapolis_sector_data.csv', 'R2_indianapolis_sector_data.csv'],\n",
    "    ['R1_road_america_sector_data.csv', 'R2_road_america_sector_data.csv'],\n",
    "    ['R1_sebring_sector_data.csv', 'R2_sebring_sector_data.csv'],\n",
    "    ['R1_sonoma_sector_data.csv', 'R2_sonoma_sector_data.csv'],\n",
    "    ['R1_vir_sector_data.csv', 'R2_vir_sector_data.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_track_id = [\"I_R06_2025-09-07\", \"I_R02_2025-04-27\", \"I_R07_2025-10-19\", \"I_R05_2025-08-17\", \"I_R03_2025-05-18\", \"I_R01_2025-03-30\", \"I_R04_2025-07-20\"]\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_t_id, r_n, list_i_path, list_o_path in zip(race_track, race_track_id, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t, r_t_id), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            test_df = pd.read_csv(\n",
    "                f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                usecols=[\"NUMBER\", \" LAP_NUMBER\", \" LAP_TIME\", \" LAP_IMPROVEMENT\", \" CROSSING_FINISH_LINE_IN_PIT\", \" S1\", \" S1_IMPROVEMENT\", \" S2\", \" S2_IMPROVEMENT\", \" S3\", \" S3_IMPROVEMENT\", \" KPH\", \" ELAPSED\", \" HOUR\", \"S1_LARGE\", \"S2_LARGE\", \"S3_LARGE\", \"TOP_SPEED\", \"PIT_TIME\", \"S1_SECONDS\", \"S2_SECONDS\", \"S3_SECONDS\", \"IM1a_time\", \"IM1a_elapsed\", \"IM2a_time\", \"IM2a_elapsed\", \"IM3a_time\", \"IM3a_elapsed\", \"FL_time\", \"FL_elapsed\"],\n",
    "                sep=\";\",\n",
    "                dtype={'NUMBER': str}\n",
    "            )\n",
    "            test_df[\"meta_event\"] = r_t_id\n",
    "            test_df[\"meta_session\"] = f\"R{s}\"\n",
    "            \n",
    "            COLUMNS_TO_CHANGE = [col for col in test_df.columns if col not in [\"meta_event\", \"meta_session\", \"NUMBER\", \" HOUR\"]]\n",
    "            \n",
    "            test_df[COLUMNS_TO_CHANGE] = convert_columns(test_df[COLUMNS_TO_CHANGE])\n",
    "            test_df = test_df[[\"meta_event\", \"meta_session\", *[col for col in test_df.columns if col not in [\"meta_event\", \"meta_session\"]]]]\n",
    "            test_df.columns = [col.strip().lower() for col in test_df.columns]\n",
    "\n",
    "            test_df.to_csv(\n",
    "                f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d855661",
   "metadata": {},
   "source": [
    "### t_telemetry_data (telemetry_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6aeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_header_pandas(filename):\n",
    "    \"\"\"Gets the CSV header. Handles file-not-found exceptions.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename, nrows=0) \n",
    "        return df.columns.tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {filename}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: Input file is empty at {filename}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading header from {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"Applies the JSON transformation logic to a single chunk of data.\"\"\"\n",
    "    # Ensure 'value' column is string type before applying json.loads\n",
    "    # 'errors' handles any bad data that might not be valid JSON\n",
    "    chunk['value'] = chunk['value'].astype(str).apply(lambda x: json.loads(x) if x.strip() else None)\n",
    "    \n",
    "    # Drop rows where JSON was null or empty\n",
    "    exploded_chunk = chunk.dropna(subset=['value']).explode('value')\n",
    "    normalized_details = pd.json_normalize(exploded_chunk['value']).add_prefix('telemetry_')\n",
    "    \n",
    "    exploded_chunk = exploded_chunk.reset_index(drop=True)\n",
    "    normalized_details = normalized_details.reset_index(drop=True)\n",
    "    \n",
    "    processed_chunk = pd.concat([exploded_chunk.drop('value', axis=1), normalized_details], axis=1)\n",
    "    return processed_chunk\n",
    "\n",
    "\n",
    "def fetch_and_save_telemetry(meta_event, meta_session, input_file_path, output_file_path, chunk_size):\n",
    "\n",
    "    print(f\"  Starting processing for: {input_file_path}\")\n",
    "    headers = get_csv_header_pandas(input_file_path)\n",
    "    if headers is None:\n",
    "        return\n",
    "\n",
    "    needs_transformation = \"value\" in headers\n",
    "    cols_to_drop = ['expire_at', 'meta_source', 'meta_event', 'meta_session', 'meta_time', 'outing', 'original_vehicle_id', 'vehicle_number']\n",
    "    pivot_index = [\"lap\", \"timestamp\", \"vehicle_id\"]\n",
    "    final_desired_cols = [\n",
    "        'meta_event', 'meta_session', \"lap\", \"timestamp\", \"vehicle_id\",\n",
    "        'Steering_Angle', 'accx_can', 'accy_can', 'ath', 'gear', \n",
    "        'nmot', 'pbrake_f', 'pbrake_r', 'speed'\n",
    "    ]\n",
    "\n",
    "    all_pivoted_chunks = []\n",
    "\n",
    "    try:\n",
    "        for chunk in pd.read_csv(input_file_path, chunksize=chunk_size,\n",
    "                                 dtype={\"vehicle_id\": str},\n",
    "                                 usecols=lambda col: col not in cols_to_drop):\n",
    "            if needs_transformation:\n",
    "                processed_chunk = process_chunk(chunk)\n",
    "            else:\n",
    "                chunk['telemetry_name'] = chunk['telemetry_name'].astype(str)\n",
    "                processed_chunk = chunk\n",
    "\n",
    "            try:\n",
    "                pivot_df = processed_chunk.pivot_table(\n",
    "                    index=pivot_index,\n",
    "                    columns=\"telemetry_name\",\n",
    "                    values=\"telemetry_value\",\n",
    "                    aggfunc=\"mean\"\n",
    "                )\n",
    "                all_pivoted_chunks.append(pivot_df)\n",
    "            except KeyError as e:\n",
    "                print(f\"    Warning: Chunk missing expected column for pivot: {e}. Skipping chunk.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Error during pivot: {e}. Skipping chunk.\")\n",
    "\n",
    "\n",
    "        if not all_pivoted_chunks:\n",
    "            print(f\"  No valid data processed for {input_file_path}. Output file will not be created.\")\n",
    "            return\n",
    "\n",
    "        # Concatenate all sparse chunks\n",
    "        print(\"    Concatenating all processed chunks...\")\n",
    "        combined_pivots = pd.concat(all_pivoted_chunks)\n",
    "\n",
    "        # \"Collapse\" the sparse data\n",
    "        print(\"    Collapsing sparse data... (this may take a moment)\")\n",
    "        index_levels = list(range(len(pivot_index)))\n",
    "        final_agg_df = combined_pivots.groupby(level=index_levels).mean()\n",
    "        \n",
    "        # Clean up the DataFrame\n",
    "        final_agg_df.columns.name = None\n",
    "        final_agg_df = final_agg_df.reset_index()\n",
    "\n",
    "        # Add 'meta_event' and 'meta_session'\n",
    "        final_agg_df.loc[:, 'meta_event'] = meta_event\n",
    "        final_agg_df.loc[:, 'meta_session'] = f\"R{meta_session}\"\n",
    "\n",
    "        # Reindex columns filling in 'NaN' for any telemetry data missing in this file\n",
    "        existing_cols = [col for col in final_desired_cols if col in final_agg_df.columns]\n",
    "        final_df = final_agg_df[existing_cols]\n",
    "\n",
    "        for col in final_desired_cols:\n",
    "            if col not in final_df.columns:\n",
    "                final_df.loc[:, col] = np.nan\n",
    "        \n",
    "        final_df = final_df[final_desired_cols]\n",
    "\n",
    "        output_dir = os.path.dirname(output_file_path)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"    Created directory: {output_dir}\")\n",
    "\n",
    "        final_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"  Successfully processed and saved to {output_file_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  FATAL ERROR processing {input_file_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c86d19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 1 ('R1_barber_telemetry_data.csv', 'R1_barber_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\barber-motorsports-park\\barber\\Race 1\\R1_barber_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihar\\AppData\\Local\\Temp\\ipykernel_3036\\1071547361.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:, col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully processed and saved to transformed_dataset\\barber-motorsports-park\\Race 1\\R1_barber_telemetry_data.csv\n",
      "\n",
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 2 ('R2_barber_telemetry_data.csv', 'R2_barber_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\barber-motorsports-park\\barber\\Race 2\\R2_barber_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihar\\AppData\\Local\\Temp\\ipykernel_3036\\1071547361.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:, col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully processed and saved to transformed_dataset\\barber-motorsports-park\\Race 2\\R2_barber_telemetry_data.csv\n",
      "\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 1 ('R1_cota_telemetry_data.csv', 'R1_cota_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\circuit-of-the-americas\\COTA\\Race 1\\R1_cota_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\circuit-of-the-americas\\Race 1\\R1_cota_telemetry_data.csv\n",
      "\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 2 ('R2_cota_telemetry_data.csv', 'R2_cota_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\circuit-of-the-americas\\COTA\\Race 2\\R2_cota_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\circuit-of-the-americas\\Race 2\\R2_cota_telemetry_data.csv\n",
      "\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 1 ('R1_indianapolis_motor_speedway_telemetry.csv', 'R1_indianapolis_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\indianapolis\\indianapolis\\Race 1\\R1_indianapolis_motor_speedway_telemetry.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihar\\AppData\\Local\\Temp\\ipykernel_3036\\1071547361.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:, col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully processed and saved to transformed_dataset\\indianapolis\\Race 1\\R1_indianapolis_telemetry_data.csv\n",
      "\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 2 ('R2_indianapolis_motor_speedway_telemetry.csv', 'R2_indianapolis_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\indianapolis\\indianapolis\\Race 2\\R2_indianapolis_motor_speedway_telemetry.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihar\\AppData\\Local\\Temp\\ipykernel_3036\\1071547361.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.loc[:, col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully processed and saved to transformed_dataset\\indianapolis\\Race 2\\R2_indianapolis_telemetry_data.csv\n",
      "\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 1 ('R1_road_america_telemetry_data.csv', 'R1_road_america_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\road-america\\Road America\\Race 1\\R1_road_america_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\road-america\\Race 1\\R1_road_america_telemetry_data.csv\n",
      "\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 2 ('R2_road_america_telemetry_data.csv', 'R2_road_america_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\road-america\\Road America\\Race 2\\R2_road_america_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\road-america\\Race 2\\R2_road_america_telemetry_data.csv\n",
      "\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 1 ('sebring_telemetry_R1.csv', 'R1_sebring_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\sebring\\Sebring\\Race 1\\sebring_telemetry_R1.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\sebring\\Race 1\\R1_sebring_telemetry_data.csv\n",
      "\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 2 ('sebring_telemetry_R2.csv', 'R2_sebring_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\sebring\\Sebring\\Race 2\\sebring_telemetry_R2.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\sebring\\Race 2\\R2_sebring_telemetry_data.csv\n",
      "\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 1 ('sonoma_telemetry_R1.csv', 'R1_sonoma_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\sonoma\\Sonoma\\Race 1\\sonoma_telemetry_R1.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\sonoma\\Race 1\\R1_sonoma_telemetry_data.csv\n",
      "\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 2 ('sonoma_telemetry_R2.csv', 'R2_sonoma_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\sonoma\\Sonoma\\Race 2\\sonoma_telemetry_R2.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\sonoma\\Race 2\\R2_sonoma_telemetry_data.csv\n",
      "\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 1 ('R1_vir_telemetry_data.csv', 'R1_vir_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\virginia-international-raceway\\VIR\\Race 1\\R1_vir_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\virginia-international-raceway\\Race 1\\R1_vir_telemetry_data.csv\n",
      "\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 2 ('R2_vir_telemetry_data.csv', 'R2_vir_telemetry_data.csv')\n",
      "  Starting processing for: dataset\\virginia-international-raceway\\VIR\\Race 2\\R2_vir_telemetry_data.csv\n",
      "    Concatenating all processed chunks...\n",
      "    Collapsing sparse data... (this may take a moment)\n",
      "  Successfully processed and saved to transformed_dataset\\virginia-international-raceway\\Race 2\\R2_vir_telemetry_data.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file_name = [\n",
    "    ['R1_barber_telemetry_data.csv', 'R2_barber_telemetry_data.csv'],\n",
    "    ['R1_cota_telemetry_data.csv', 'R2_cota_telemetry_data.csv'],\n",
    "    ['R1_indianapolis_motor_speedway_telemetry.csv', 'R2_indianapolis_motor_speedway_telemetry.csv'],\n",
    "    ['R1_road_america_telemetry_data.csv', 'R2_road_america_telemetry_data.csv'],\n",
    "    ['sebring_telemetry_R1.csv', 'sebring_telemetry_R2.csv'],\n",
    "    ['sonoma_telemetry_R1.csv', 'sonoma_telemetry_R2.csv'],\n",
    "    ['R1_vir_telemetry_data.csv', 'R2_vir_telemetry_data.csv']\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_telemetry_data.csv', 'R2_barber_telemetry_data.csv'],\n",
    "    ['R1_cota_telemetry_data.csv', 'R2_cota_telemetry_data.csv'],\n",
    "    ['R1_indianapolis_telemetry_data.csv', 'R2_indianapolis_telemetry_data.csv'],\n",
    "    ['R1_road_america_telemetry_data.csv', 'R2_road_america_telemetry_data.csv'],\n",
    "    ['R1_sebring_telemetry_data.csv', 'R2_sebring_telemetry_data.csv'],\n",
    "    ['R1_sonoma_telemetry_data.csv', 'R2_sonoma_telemetry_data.csv'],\n",
    "    ['R1_vir_telemetry_data.csv', 'R2_vir_telemetry_data.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_track_id = [\"I_R06_2025-09-07\", \"I_R02_2025-04-27\", \"I_R07_2025-10-19\", \"I_R05_2025-08-17\", \"I_R03_2025-05-18\", \"I_R01_2025-03-30\", \"I_R04_2025-07-20\"]\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_t_id, r_n, list_i_path, list_o_path in zip(race_track, race_track_id, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t, r_t_id), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            chunk_size=50000 # Increased chunk size for better performance\n",
    "\n",
    "            fetch_and_save_telemetry(\n",
    "                meta_event=r_t_id,\n",
    "                meta_session=s,\n",
    "                input_file_path=f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                output_file_path=f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                chunk_size=chunk_size\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9a08c",
   "metadata": {},
   "source": [
    "### t_weather_data (weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01080b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_barber_weather_data.csv')\n",
      "--> ('barber-motorsports-park', 'I_R06_2025-09-07') barber 2 ('26_Weather_Race 2_Anonymized.CSV', 'R2_barber_weather_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_cota_weather_data.csv')\n",
      "--> ('circuit-of-the-americas', 'I_R02_2025-04-27') COTA 2 ('26_Weather_ Race 2_Anonymized.CSV', 'R2_cota_weather_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 1 ('26_Weather_Race 1.CSV', 'R1_indianapolis_weather_data.csv')\n",
      "--> ('indianapolis', 'I_R07_2025-10-19') indianapolis 2 ('26_Weather_Race 2.CSV', 'R2_indianapolis_weather_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_road_america_weather_data.csv')\n",
      "--> ('road-america', 'I_R05_2025-08-17') Road America 2 ('26_Weather_Race 2_Anonymized.CSV', 'R2_road_america_weather_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_sebring_weather_data.csv')\n",
      "--> ('sebring', 'I_R03_2025-05-18') Sebring 2 ('26_Weather_Race 2_Anonymized.CSV', 'R2_sebring_weather_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_sonoma_weather_data.csv')\n",
      "--> ('sonoma', 'I_R01_2025-03-30') Sonoma 2 ('26_Weather_ Race 2.csv', 'R2_sonoma_weather_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 1 ('26_Weather_Race 1_Anonymized.CSV', 'R1_vir_weather_data.csv')\n",
      "--> ('virginia-international-raceway', 'I_R04_2025-07-20') VIR 2 ('26_Weather_Race 2_Anonymized.CSV', 'R2_vir_weather_data.csv')\n"
     ]
    }
   ],
   "source": [
    "input_file_name = [\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_Race 2_Anonymized.CSV'],\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_ Race 2_Anonymized.CSV'],\n",
    "    ['26_Weather_Race 1.CSV', '26_Weather_Race 2.CSV'],\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_Race 2_Anonymized.CSV'],\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_Race 2_Anonymized.CSV'],\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_ Race 2.csv'],\n",
    "    ['26_Weather_Race 1_Anonymized.CSV', '26_Weather_Race 2_Anonymized.CSV']\n",
    "]\n",
    "output_file_name = [\n",
    "    ['R1_barber_weather_data.csv', 'R2_barber_weather_data.csv'],\n",
    "    ['R1_cota_weather_data.csv', 'R2_cota_weather_data.csv'],\n",
    "    ['R1_indianapolis_weather_data.csv', 'R2_indianapolis_weather_data.csv'],\n",
    "    ['R1_road_america_weather_data.csv', 'R2_road_america_weather_data.csv'],\n",
    "    ['R1_sebring_weather_data.csv', 'R2_sebring_weather_data.csv'],\n",
    "    ['R1_sonoma_weather_data.csv', 'R2_sonoma_weather_data.csv'],\n",
    "    ['R1_vir_weather_data.csv', 'R2_vir_weather_data.csv']\n",
    "]\n",
    "race_track = ['barber-motorsports-park', 'circuit-of-the-americas', 'indianapolis', 'road-america', 'sebring', 'sonoma', 'virginia-international-raceway']\n",
    "race_track_id = [\"I_R06_2025-09-07\", \"I_R02_2025-04-27\", \"I_R07_2025-10-19\", \"I_R05_2025-08-17\", \"I_R03_2025-05-18\", \"I_R01_2025-03-30\", \"I_R04_2025-07-20\"]\n",
    "race_name = ['barber', 'COTA', 'indianapolis', 'Road America', 'Sebring', 'Sonoma', 'VIR']\n",
    "race_session = [1, 2]\n",
    "\n",
    "for r_t, r_t_id, r_n, list_i_path, list_o_path in zip(race_track, race_track_id, race_name, input_file_name, output_file_name):\n",
    "    for s, i_name, o_name in zip(race_session, list_i_path, list_o_path):\n",
    "        print(\"-->\", (r_t, r_t_id), r_n, s, (i_name, o_name))\n",
    "        try:\n",
    "            test_df = pd.read_csv(\n",
    "                f\"dataset\\\\{r_t}\\\\{r_n}\\\\Race {s}\\\\{i_name}\",\n",
    "                usecols=[\"TIME_UTC_SECONDS\", \"AIR_TEMP\", \"TRACK_TEMP\", \"HUMIDITY\", \"PRESSURE\", \"WIND_SPEED\", \"WIND_DIRECTION\", \"RAIN\"],\n",
    "                sep=\";\"\n",
    "            )\n",
    "            test_df[\"meta_event\"] = r_t_id\n",
    "            test_df[\"meta_session\"] = f\"R{s}\"\n",
    "            \n",
    "            test_df[\"TIME_UTC_SECONDS\"] = pd.to_datetime(test_df[\"TIME_UTC_SECONDS\"], unit='s', utc=True)\n",
    "            test_df.rename(columns={\"TIME_UTC_SECONDS\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "            test_df[\"AIR_TEMP\"] = test_df[\"AIR_TEMP\"].astype(float)\n",
    "            test_df[\"TRACK_TEMP\"] = test_df[\"TRACK_TEMP\"].astype(float)\n",
    "            test_df[\"HUMIDITY\"] = test_df[\"HUMIDITY\"].astype(float)\n",
    "            test_df[\"PRESSURE\"] = test_df[\"PRESSURE\"].astype(float)\n",
    "            test_df[\"WIND_SPEED\"] = test_df[\"WIND_SPEED\"].astype(float)\n",
    "            test_df[\"WIND_DIRECTION\"] = test_df[\"WIND_DIRECTION\"].astype(int)\n",
    "            test_df[\"RAIN\"] = test_df[\"RAIN\"].astype(float)\n",
    "\n",
    "            test_df.columns = [col.strip().lower() for col in test_df.columns]\n",
    "            test_df = test_df[[\"meta_event\", \"meta_session\", *[col for col in test_df.columns if col not in [\"meta_event\", \"meta_session\"]]]]\n",
    "\n",
    "            test_df.to_csv(\n",
    "                f\"transformed_dataset\\\\{r_t}\\\\Race {s}\\\\{o_name}\",\n",
    "                index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"error at {r_t, r_n, s} :\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffc06d",
   "metadata": {},
   "source": [
    "### t_driver_info_data & t_driver_championship_data (driver_info_data & driver_championship_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b3a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    r\"dataset\\indianapolis\\indianapolis\\GR Drivers Championship-1.csv\",\n",
    "    sep=\";\",\n",
    "    dtype={'Number': str},\n",
    "    usecols= lambda x : x != 'Unnamed: 192'\n",
    ")\n",
    "\n",
    "# Rename 'Points' to 'TotalPoints' to avoid the collision in names.\n",
    "if 'Points' in test_df.columns:\n",
    "    test_df = test_df.rename(columns={'Points': 'TotalPoints'})\n",
    "\n",
    "# ================================\n",
    "# TABLE 1  Overall driver info\n",
    "# ================================\n",
    "overall_cols = [\n",
    "    \"Pos\", \"Participant\", \"TotalPoints\", \"Number\", \"NAME\",\n",
    "    \"SURNAME\", \"COUNTRY\", \"TEAM\", \"MANUFACTURER\", \"CLASS\"\n",
    "]\n",
    "overall_df = test_df[overall_cols].copy()\n",
    "\n",
    "\n",
    "# The URL to request\n",
    "url = \"https://www.grcupseries.com/drivers?filter_season_id=3&filter_text=\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all <a> tags with class=\"drivers__list-link\"\n",
    "links = soup.find_all(\"a\", class_=\"drivers__list-link\")\n",
    "\n",
    "driver_info = {}\n",
    "for link in links:\n",
    "    name = link.find(\"h3\").text\n",
    "    value = link.find(\"img\")['src']\n",
    "    driver_info[name] = value\n",
    "\n",
    "overall_df['Driver_Image_URL'] = overall_df['Participant'].map(driver_info)\n",
    "\n",
    "# =======================================\n",
    "# TABLE 2  Race-wise granular details\n",
    "# =======================================\n",
    "\n",
    "cols_to_unpivot = [col for col in test_df.columns.tolist() if '_' in col]\n",
    "detail_df = test_df.drop(columns=['Pos']).melt(id_vars=['Number', 'NAME'], value_vars=cols_to_unpivot)\n",
    "detail_df[['race_track', 'race_session', 'points_type']] = detail_df['variable'].str.split('_', expand=True)\n",
    "detail_df = detail_df.drop('variable', axis=1)\n",
    "detail_df = detail_df.pivot(index=['Number', 'NAME', 'race_track', 'race_session'], columns=['points_type'], values=['value']).reindex()\n",
    "detail_df.columns = [col for (value, col) in detail_df.columns]\n",
    "detail_df = detail_df.reset_index()\n",
    "detail_df\n",
    "\n",
    "# =======================================\n",
    "# TABLE 3  Team Info details\n",
    "# =======================================\n",
    "\n",
    "team_info = {\n",
    "    'BSI Racing': 'https://images.squarespace-cdn.com/content/v1/67c806662f822b0c4767cc08/0a223190-97e7-48a8-bc86-1a02b720e510/BSI-logo-longversion-white.png?format=1500w',\n",
    "    'Copeland Motorsports': 'https://www.rtd-media.com/wp-content/uploads/2019/12/19-12-02-copeland-logo.jpg',\n",
    "    'RVA Graphics Motorsports by Speed Syndicate': 'https://rvagraphicsmotorsports.com/wp-content/uploads/2024/06/rva_gfx_logo.webp',\n",
    "    'Lucas Racing': 'https://lucasracing.com/cdn/shop/files/IMG_0078_1_250x.jpg?v=1648172374',\n",
    "    'TechSport': 'https://cdn.prod.website-files.com/5e415de58278d0a29004f4e3/5e4af0469ad7736eb0663548_TechSport%20Racing%20Wordmark%20Logo%20Stacked.png',\n",
    "    'Nitro Motorsports': 'https://www.racenitro.com/wp-content/uploads/2025/02/Nitro-Motorsports-logo-white.png',\n",
    "    'PT Autosport with Copeland Motorsports': 'https://ptautosport.com/wp-content/uploads/2022/08/PT-Autosport-logo.svg',\n",
    "    'Mashore Autobody': 'https://scontent-lga3-2.xx.fbcdn.net/v/t39.30808-6/305842688_592167659279363_2622203305532223756_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=6ee11a&_nc_ohc=HuwSgXnq9WUQ7kNvwGeH2wg&_nc_oc=AdnBzYWpmg8d0Y3ssPDiIhwgym4TTGItJ3_e0SYDz1pHw4M-7xq0t5cch_xXLYEzrUyrZ-rKvCmCgwXaWC_65qNS&_nc_zt=23&_nc_ht=scontent-lga3-2.xx&_nc_gid=Dg48dDAGdAVlxVMO3hRkPg&oh=00_AfiHO975st5cn0OuiY7xgLwnosNGYW_ICzloW1l_dieZ5g&oe=69195BBD',\n",
    "    'Eagles Canyon Racing Powered by Fast Track': 'https://eaglescanyon.com/wp-content/uploads/2017/12/LOGO.png',\n",
    "    'Skip Barber Racing': 'https://www.skipbarber.com/wp-content/uploads/2025/08/Skip-Barber-Racing-School-Logo.png',\n",
    "    'Precision Racing LA': 'https://cdn.prod.website-files.com/62f55ce641870dea1f745803/633c9028bfe1bdbe9179eb2a_Precision%20Racing%20LA%20-%20Logos-02.png',\n",
    "    'van der Steur Racing': 'https://static.wixstatic.com/media/0f2b1c_310fc4cc77e94ba4bb7902c2869ddd49~mv2.png'\n",
    "}\n",
    "\n",
    "team_df = pd.DataFrame(data=[team_info.keys(), team_info.values()]).T\n",
    "team_df.columns = ['Team', 'Team_URL']\n",
    "team_df\n",
    "\n",
    "# =========\n",
    "# Save\n",
    "# =========\n",
    "overall_df.to_csv(\n",
    "    r\"transformed_dataset\\GR_Cup_driver_info_data.csv\",\n",
    "    index=False\n",
    ")\n",
    "detail_df.to_csv(\n",
    "    r\"transformed_dataset\\GR_Cup_race_points_data.csv\",\n",
    "    index=False\n",
    ")\n",
    "team_df.to_csv(\n",
    "    r\"transformed_dataset\\GR_Cup_team_data.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbab92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
